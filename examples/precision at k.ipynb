{
 "metadata": {
  "language": "Julia",
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using LowRankModels, DataFrames, Gadfly\n",
      "\n",
      "function plot(df, x::Symbol, y::Array{Symbol}; scale = :linear, filename=None, height=3, width=6)\n",
      "    dflong = vcat(map(l->stack(df,l,x),y)...)\n",
      "    if scale ==:log\n",
      "        p = plot(dflong,x=x,y=:value,color=:variable,Scale.y_log10)\n",
      "    else\n",
      "        p = plot(dflong,x=x,y=:value,color=:variable)\n",
      "    end \t\n",
      "\tif filename\n",
      "\t\tprintln(\"saving figure in $filename\")\n",
      "\t\tdraw(PDF(filename, width*inch, height*inch), p) \n",
      "\tend\n",
      "\treturn p\n",
      "end\n",
      "\n",
      "function precision_at_k(train_glrm::GLRM, test_observed_features; params=Params(), reg_params=logspace(2,-2,5), \n",
      "                        holdout_proportion=.1, verbose=true,\n",
      "                        ch::ConvergenceHistory=ConvergenceHistory(\"reg_path\"))\n",
      "    m,n = size(train_glrm.A)\n",
      "    println(map(length, train_glrm.observed_features))\n",
      "    println(map(length, test_observed_features))\n",
      "    ntrain = sum(map(length, train_glrm.observed_features))\n",
      "    ntest = sum(map(length, test_observed_features))\n",
      "    println(ntest+ntrain)\n",
      "    train_error = Array(Float64, length(reg_params))\n",
      "    prec_at_k = Array(Float64, length(reg_params))\n",
      "    solution = Array((Float64,Float64), length(reg_params))\n",
      "    train_time = Array(Float64, length(reg_params))\n",
      "    for iparam=1:length(reg_params)\n",
      "        reg_param = reg_params[iparam]\n",
      "        # evaluate train error\n",
      "        if verbose println(\"fitting train GLRM for reg_param $reg_param\") end\n",
      "        train_glrm.rx.scale, train_glrm.ry.scale = reg_param, reg_param\n",
      "        train_glrm.X, train_glrm.Y = randn(m,train_glrm.k), randn(train_glrm.k,n)\n",
      "        X, Y, ch = fit!(train_glrm, params, ch, verbose=verbose)\n",
      "        train_time[iparam] = ch.times[end]\n",
      "        if verbose println(\"computing train error and precision at k for reg_param $reg_param:\") end\n",
      "        train_error[iparam] = objective(train_glrm, X, Y, include_regularization=false) / ntrain\n",
      "        if verbose println(\"\\ttrain error: $(train_error[iparam])\") end\n",
      "        # precision at k\n",
      "        XY = X*Y\n",
      "        q = sort(XY[:],rev=true)[ntest+ntrain] # the ntest+ntrain largest value in the model XY\n",
      "        true_pos = 0; false_pos = 0\n",
      "        for i=1:m\n",
      "            for j=1:n\n",
      "                if XY[i,j] >= q\n",
      "                    if j in test_observed_features[i]\n",
      "                        true_pos += 1\n",
      "                    elseif !(j in train_observed_features[i])\n",
      "                        false_pos += 1\n",
      "                    end\n",
      "                end\n",
      "            end\n",
      "        end\n",
      "        prec_at_k[iparam] = true_pos / (true_pos + false_pos)\n",
      "        if verbose println(\"\\prec_at_k:  $(prec_at_k[iparam])\") end\n",
      "        solution[iparam] = (sum(X)+sum(Y), sum(abs(X))+sum(abs(Y)))\n",
      "        if verbose println(\"\\tsum of solution, one norm of solution:  $(solution[iparam])\") end\n",
      "    end\n",
      "    return train_error, prec_at_k, train_time, reg_params, solution\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# boolean example with only entries greater than threshold t observed\n",
      "# ie, censored data\n",
      "# example with only entries greater than threshold t observed\n",
      "m,n,k,ktrue = 100,100,1,1\n",
      "A = rand(m,ktrue)*rand(ktrue,n)\n",
      "println(\"max value of A is \",maximum(maximum(A)),\" which is less than $ktrue\")\n",
      "B = int(ktrue*rand(m,n) .>= A) # Bernoulli samples with probability proportional to A\n",
      "losses = fill(quadratic(),n)\n",
      "r = quadreg(.1)\n",
      "obs = (Int64,Int64)[]\n",
      "for i=1:m\n",
      "    for j=1:n\n",
      "        if B[i,j] == 1\n",
      "            push!(obs, (i,j))\n",
      "        end\n",
      "    end\n",
      "end\n",
      "\n",
      "(train_observed_features, train_observed_examples, test_observed_features,  test_observed_examples) = \n",
      "    get_train_and_test(obs, m, n, .2)\n",
      "train_glrm = GLRM(B,train_observed_features, train_observed_examples,losses,r,r,k)\n",
      "\n",
      "train_error, prec_at_k, train_time, reg_params, solution = \n",
      "    precision_at_k(train_glrm, test_observed_features, params=Params(1,200,.00001,.01), \n",
      "                                 reg_params=logspace(2,-2,9))   \n",
      "df = DataFrame(train_error = train_error, prec_at_k = prec_at_k,\n",
      "                   train_time = train_time, reg_param = reg_params, solution_1norm = [s[2] for s in solution])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = plot(df, :reg_param, [:train_error, :prec_at_k], \n",
      "         scale = :linear, filename=\"prec_at_k_jnb.pdf\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}